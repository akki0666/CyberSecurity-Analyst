
# Guide on Using the ELK Stack (Elasticsearch, Logstash, Kibana)

## 1. Introduction to ELK Stack
The **ELK Stack** consists of:
- **Elasticsearch**: A search engine for storing and retrieving log data.
- **Logstash**: A data processing pipeline for ingesting, transforming, and sending data.
- **Kibana**: A visualization tool for querying Elasticsearch and building dashboards.

## 2. Installing the ELK Stack

### 2.1 Installing Elasticsearch
1. **Download and Install Elasticsearch**:
   - Ensure **Java 8+** is installed.
   ```bash
   wget https://artifacts.elastic.co/downloads/elasticsearch/elasticsearch-7.x.x-linux-x86_64.tar.gz
   tar -xzf elasticsearch-7.x.x-linux-x86_64.tar.gz
   cd elasticsearch-7.x.x
   ```

2. **Configure Elasticsearch** in `elasticsearch.yml`:
   ```yaml
   network.host: 0.0.0.0
   cluster.name: my-cluster
   node.name: my-node
   ```

3. **Start Elasticsearch**:
   ```bash
   ./bin/elasticsearch
   ```

4. **Access Elasticsearch**:
   Navigate to `http://localhost:9200` to verify Elasticsearch is running.

### 2.2 Installing Logstash
1. **Download and Install Logstash**:
   ```bash
   wget https://artifacts.elastic.co/downloads/logstash/logstash-7.x.x-linux-x86_64.tar.gz
   tar -xzf logstash-7.x.x-linux-x86_64.tar.gz
   cd logstash-7.x.x
   ```

2. **Create a Logstash Configuration (`logstash.conf`)**:
   ```bash
   input {
     file {
       path => "/var/log/syslog"
       start_position => "beginning"
     }
   }
   
   filter {
     grok {
       match => { "message" => "%{SYSLOGBASE} %{GREEDYDATA:logmessage}" }
     }
   }
   
   output {
     elasticsearch {
       hosts => ["localhost:9200"]
       index => "syslog-%{+YYYY.MM.dd}"
     }
   }
   ```

3. **Start Logstash** with the configuration file:
   ```bash
   ./bin/logstash -f /path/to/logstash.conf
   ```

### 2.3 Installing Kibana
1. **Download and Install Kibana**:
   ```bash
   wget https://artifacts.elastic.co/downloads/kibana/kibana-7.x.x-linux-x86_64.tar.gz
   tar -xzf kibana-7.x.x-linux-x86_64.tar.gz
   cd kibana-7.x.x
   ```

2. **Configure Kibana (`kibana.yml`)**:
   ```yaml
   server.port: 5601
   server.host: "0.0.0.0"
   elasticsearch.hosts: ["http://localhost:9200"]
   ```

3. **Start Kibana**:
   ```bash
   ./bin/kibana
   ```

4. **Access Kibana**:
   Open `http://localhost:5601` in your browser to access the Kibana dashboard.

## 3. ELK Stack Workflow

1. **Log Collection**: Data is collected from various sources using **Logstash** or **Beats**.
2. **Data Parsing and Transformation**: Logstash applies filters to transform data.
3. **Data Storage**: Transformed data is stored and indexed in **Elasticsearch**.
4. **Data Visualization**: Data in Elasticsearch is visualized in **Kibana**.

## 4. Basic Usage of ELK Stack

### 4.1 Ingesting Data via Logstash
Create a Logstash configuration to ingest logs:
```bash
input {
  beats {
    port => 5044
  }
}

filter {
  grok {
    match => { "message" => "%{COMMONAPACHELOG}" }
  }
}

output {
  elasticsearch {
    hosts => ["localhost:9200"]
    index => "apache-logs-%{+YYYY.MM.dd}"
  }
}
```

Start Logstash:
```bash
./bin/logstash -f logstash.conf
```

### 4.2 Visualizing Data in Kibana
1. **Access Kibana** at `http://localhost:5601`.
2. **Create an Index Pattern**:
   - Go to **Management** > **Index Patterns** and create an index pattern like `apache-logs-*`.
3. **Create Visualizations** in the **Visualize** tab, selecting data from your index pattern.
4. **Create Dashboards** by combining visualizations into a comprehensive view.

## 5. Advanced Features in ELK Stack

### 5.1 Data Enrichment with Logstash Filters
Logstash provides multiple filters to enrich data:
- **Grok**: Extract fields from unstructured log data.
- **GeoIP**: Add geographical information based on IP addresses.

**Example Grok Filter**:
```bash
filter {
  grok {
    match => { "message" => "%{IP:client} %{USER:ident} %{USER:auth} \[%{HTTPDATE:timestamp}\] "%{WORD:method} %{DATA:request} HTTP/%{NUMBER:httpversion}" %{NUMBER:response} %{NUMBER:bytes}" }
  }
}
```

### 5.2 Elasticsearch Queries (DSL)
You can perform advanced searches using **Elasticsearch Query DSL**.

**Example Query**:
```json
GET /apache-logs-*/_search
{
  "query": {
    "match": {
      "response": 404
    }
  }
}
```

### 5.3 Kibana Alerts and Anomaly Detection
Kibana allows you to set alerts based on conditions:
1. Go to **Alerts and Actions** in Kibana.
2. Create a new alert with conditions, such as detecting `response=404`.
3. Set notifications (e.g., email or Slack).

### 5.4 Scaling and Clustering
To handle large volumes of data, Elasticsearch supports clustering:
- **Master Nodes**: Manage the cluster.
- **Data Nodes**: Store and process data.
- **Ingest Nodes**: Pre-process data before indexing.

